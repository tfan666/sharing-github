---
title: "Practial Machine Learning Course Project"
author: "Tongtian Fan"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    keep_md: true
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

This project aims to use the data collected in the data and build a predictive model to predict the `classe`. The analysis contains data pre-processing, exploratory data analysis, model selections, and final model predcitions.


## Data Pre-processing

In this section, my approaches are:

- Load data and packages
```{r , warning=F, message=F}

library('readr')
library('caret')
library('dplyr')
library('GGally')
library('Metrics')
library('ggplot2')
data <- read_csv('pml-training.csv')

```
- Check num of columns and rows
```{r, warning=F, message=F}
print(paste('This dataset has: ', dim(data)[2], 'columns and',
           dim(data)[1], 'rows.' ))
```
- Check num of predicted classes
```{r, warning=F, message=F}
distinct(data, classe)
```

- This rest processes only applies the training data. The train and validation spilt is 70/30.
```{r}

set.seed(666)
trainIndex <- createDataPartition(y = data$classe, 
                                  p = 0.7, 
                                  list = F,
                                  times = 1)
# split
Train <- data[trainIndex,]
Val  <- data[-trainIndex,]
```
- Remove columns whose missing perecentages are over 50%
```{r, warning=F, message=F}
# check missing pct of each variable
missing_cols = c()
for (i in c(1:dim(Train)[2])){
  missing_cols <- bind_rows(
    missing_cols,
    data.frame(
      'variable' = names(Train)[i],
      'missing_pct' = mean(is.na(Train%>%select(i)))
    )
  )
}

#remove columns with over 50% missing value 
missing_cols_rm <- missing_cols %>% 
  filter(missing_pct > 0.5) %>%
  select(variable)

for (i in missing_cols_rm){
  Train <- Train %>% 
    select(-i)
}
```
- Remove near Zero Variables 
```{r, warning=F, message=F}
# remove near0 value
near0 <- nearZeroVar(Train, names = T)

Train <- Train %>% 
  select(-near0)
```
- Remove high pairwise correlated variase by cutoff of 0.75
```{r, warning=F, message=F}
# remove cor varibale
corvar <- findCorrelation(x = Train %>%
                  select_if(is.numeric) %>% 
                  cor(), 
                cutoff = 0.75,
                names = T)

Train <- Train %>% 
  select(-corvar)
```
- Remove first 6 columns as there are more like ID# type of columns
```{r, warning=F, message=F}
#remove first 6 columns

Train <- Train %>%
  select(- c(1:6))
```

## Exploratory Data Analysis

This section aims to find the association bewteen features and labels in order to select potential useful predictors. As there are way many variables, I plot them in three rounds.

### First 10 variables + label 

```{r, warning=F, message=F, fig.width=16}

ggpairs(Train,
        columns = c(1:10,31),
        ggplot2::aes(colour=classe),
        lower = list(
          continuous = wrap("smooth", 
                            alpha = 0.3,
                            size=0.1)))
```


### Second 10 variables + label 

```{r, warning=F, message=F, fig.width=16}

ggpairs(Train,
       columns = c(11:20,31),
       ggplot2::aes(colour=classe),
       lower = list(
         continuous = wrap("smooth", 
                           alpha = 0.3,
                           size=0.1)))
```

### Last 10 variables + label 

```{r, warning=F, message=F,  fig.width=16}

ggpairs(Train,
       columns = c(21:31),
       ggplot2::aes(colour=classe),
       lower = list(
         continuous = wrap("smooth", 
                           alpha = 0.3,
                           size=0.1)))
```


From the three plots, it is hardly to find one or two variables that can effective differentiate the predicted classes. In this case, I plan to try tree models as these models are robust to learn large numbers of features. In specific, I will try the basic decision tree, a bagging tree (random forest), and a boosting tree (XG Boost). 


## Model Selection

This section aims pick the best models among decision tree, random forest, and xg boost.

In each modeling, a K-fold cross validation will be applied and the K is set to be 5. After this, the most balanced models of these three algorthim will be trained. In the end, I will use validation set to test the prediction accuracy and pick the best model.

### Decision Tree

```{r, warning=F, message=F}

set.seed(666)
control <- trainControl(method='cv',
                        number=5, 
                        savePredictions = T)

DT <- train(as.factor(classe)~ ., 
            data=Train, 
            method='rpart', 
            metric= 'Accuracy',
            trControl = control)

Val <- Val %>%
  select(names(Train))

DT_pred <- predict.train(DT, 
                   Val[, DT$coefnames],
                   type = 'raw' )

accuracy(DT_pred, Val$classe)
```

### Random Forest

```{r, warning=F, message=F}

set.seed(666)
control <- trainControl(method='cv',
                        number=5, 
                        savePredictions = T)

RF <- train(as.factor(classe)~ ., 
            data=Train, 
            method='rf', 
            metric= 'Accuracy',
            trControl = control)


RF_pred <- predict(RF, 
                   Val[, RF$coefnames],
                   type = 'raw' )

accuracy(RF_pred, Val$classe)
```


### XG Boost

```{r, warning=F, message=F}

set.seed(666)
control <- trainControl(method='cv',
                        number=5, 
                        savePredictions = T)

XGB <- train(as.factor(classe)~ ., 
            data=Train, 
            method='xgbTree', 
            metric= 'Accuracy',
            trControl = control)

XGB_pred <- predict(XGB, 
                    Val[, RF$coefnames],
                   type = 'raw' )

accuracy(XGB_pred, Val$classe)
```


### Validation Accuracy Comparsions

From the model comparsions, both xg boost and random forest has decent performance. I will pick random forest as:

- Random Forest has the best validation accuracy
- Bagging models is less likely to get overfitting than boosting models

```{r, warning=F, message=F}

dt <- data.frame(
  'Model' = c('Decison Tree', 'Random Forest', 'XG Boost'),
  'Accuracy' = round(c(accuracy(DT_pred, Val$classe),
                 accuracy(RF_pred, Val$classe),
                 accuracy(XGB_pred, Val$classe)
                 ),3)
) 

ggplot(dt, aes(Model, Accuracy, fill = Model))+
  geom_bar(stat = 'identity', position = 'dodge') +
  geom_label(aes(label = Accuracy), 
            vjust=3, color="#CACFD2",fontface = "bold") +
  ggtitle('Model Performance Comparsions') +
  theme(plot.title = element_text(hjust = 0.5))+
  xlab('') + ylab('') +
  ylim(c(0,1)) +
  scale_fill_manual(values=c("#78281F","#512E5F", "#154360", "#0B5345" ))

```


### Out-of-sample Errors Estimation

The out-of-sampe estimate ranges is projected to be: 

```{r, warning=F, message=F}

range(RF$finalModel$err.rate)

```

My point estimate is :

```{r , warning=F, message=F}

1- accuracy(RF_pred, Val$classe)

```

## Final Model Prediction

Here is the final model predictions for the testing datasets.

```{r, warning=F, message=F}

Test <- read_csv('pml-testing.csv')

predict(RF, 
        Test[, RF$coefnames],
        type = 'raw' )

```


